{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypUSFfxKR2Sc"
      },
      "source": [
        "# **ANN arch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP7rJPUtR1pW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLzZLsX2S4xN",
        "outputId": "394cb562-e4e0-43a5-a2e2-c9626ec14aaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bd4780aa230>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gf0F6KVQCAG",
        "outputId": "8e79dcdb-f476-4501-cf42-0124aef277c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using:cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using:{device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMR56c4KTTTo",
        "outputId": "3e7b2624-0da1-4900-f1c7-b2737dbfe116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/fashion-mnist_train.csv.zip\n",
            "  inflating: /content/fashion-mnist_train.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/fashion-mnist_train.csv.zip\" -d \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2ORLykrnJXg",
        "outputId": "44d67821-031e-42e0-dcf2-13d5ad3cf5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uo_MtnRsbCH"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjnnnFsMm_mu"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/fashion-mnist_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdSJ2ekQnWTF"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:,1:].values\n",
        "y = df.iloc[:,0].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pmnbM38oGwe",
        "outputId": "dbd1f4ec-bde0-4e34-af27-721286eb3928"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMzOh2hToPxC"
      },
      "outputs": [],
      "source": [
        "X_train_np, X_test_np, y_train_np,  y_test_np = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc6x2kXE2D3P"
      },
      "outputs": [],
      "source": [
        "X_train_np = X_train_np/255.0\n",
        "X_test_np = X_test_np/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neYEcZYpodsl"
      },
      "outputs": [],
      "source": [
        "X_train = torch.from_numpy(X_train_np).to(dtype= torch.float32)\n",
        "y_train = torch.from_numpy(y_train_np).to(dtype = torch.long)\n",
        "X_test = torch.from_numpy(X_test_np).to(dtype= torch.float32)\n",
        "y_test = torch.from_numpy(y_test_np).to(dtype = torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0hzmyvgpwdE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4pu2frFpU5e"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(X_train_np, y_train_np)\n",
        "test_data = TensorDataset(X_test_np, y_test_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl_jPqFvrAbL"
      },
      "outputs": [],
      "source": [
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7LYGqhnql7I"
      },
      "outputs": [],
      "source": [
        "train_Loder = DataLoader(train_data, batch_size= batch_size, shuffle=True)\n",
        "test_Loder = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VoJCYxErVyr"
      },
      "outputs": [],
      "source": [
        "class MY_model(nn.Module):\n",
        "\n",
        "  def __init__(self, fetures):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(fetures, 192),\n",
        "        nn.ReLU(),\n",
        "        nn.Droupout(0.3),\n",
        "        nn.Linear(192, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Droupout(0.2),\n",
        "        nn.Linear(64, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.model(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7ybMfk00phM"
      },
      "outputs": [],
      "source": [
        "model = MY_model(X_train.shape[1]).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHzNiRS7sw-L"
      },
      "outputs": [],
      "source": [
        "lr = 0.1\n",
        "epochs = 50\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qb5bqDiuSoQ",
        "outputId": "b1782322-e6d6-476a-c121-fee7d2b2eb2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch :1 loss : 0.5520416678190231\n",
            "epoch :2 loss : 0.36683112700780235\n",
            "epoch :3 loss : 0.3152758907179038\n",
            "epoch :4 loss : 0.28567005427678427\n",
            "epoch :5 loss : 0.26120245349407195\n",
            "epoch :6 loss : 0.24688619753221672\n",
            "epoch :7 loss : 0.22751775560776394\n",
            "epoch :8 loss : 0.21157034164170424\n",
            "epoch :9 loss : 0.19941512541969617\n",
            "epoch :10 loss : 0.19119276695946852\n",
            "epoch :11 loss : 0.17866950306296348\n",
            "epoch :12 loss : 0.1703589951346318\n",
            "epoch :13 loss : 0.1662338675558567\n",
            "epoch :14 loss : 0.15797316977878412\n",
            "epoch :15 loss : 0.14893953812370697\n",
            "epoch :16 loss : 0.1406944880783558\n",
            "epoch :17 loss : 0.135050387814641\n",
            "epoch :18 loss : 0.1314353955425322\n",
            "epoch :19 loss : 0.12421898386316994\n",
            "epoch :20 loss : 0.11810431931416193\n",
            "epoch :21 loss : 0.11584915568431219\n",
            "epoch :22 loss : 0.11082605572417378\n",
            "epoch :23 loss : 0.10903052110162874\n",
            "epoch :24 loss : 0.10310673272858063\n",
            "epoch :25 loss : 0.09444742785642544\n",
            "epoch :26 loss : 0.09474585125781596\n",
            "epoch :27 loss : 0.09218672208612164\n",
            "epoch :28 loss : 0.09116713336420557\n",
            "epoch :29 loss : 0.08944754969018201\n",
            "epoch :30 loss : 0.08155423906849077\n",
            "epoch :31 loss : 0.08047178402356804\n",
            "epoch :32 loss : 0.0810886193580615\n",
            "epoch :33 loss : 0.07790866319773097\n",
            "epoch :34 loss : 0.07549514356814326\n",
            "epoch :35 loss : 0.07261165235346805\n",
            "epoch :36 loss : 0.07324393826754143\n",
            "epoch :37 loss : 0.06964357879230132\n",
            "epoch :38 loss : 0.07083059335810443\n",
            "epoch :39 loss : 0.07050121734105051\n",
            "epoch :40 loss : 0.0630751527864486\n",
            "epoch :41 loss : 0.06245125184968735\n",
            "epoch :42 loss : 0.06546741868089885\n",
            "epoch :43 loss : 0.06149973440884302\n",
            "epoch :44 loss : 0.06347622462920845\n",
            "epoch :45 loss : 0.05787842957194274\n",
            "epoch :46 loss : 0.060380808079770455\n",
            "epoch :47 loss : 0.055607400118838995\n",
            "epoch :48 loss : 0.0558973190022322\n",
            "epoch :49 loss : 0.057011533877036225\n",
            "epoch :50 loss : 0.05109369156556204\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_features, batch_labels in train_Loder:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "    logist = model(batch_features)\n",
        "    loss = criterion(logist, batch_labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  avg_loss = total_loss/len(train_Loder)\n",
        "  print(f'epoch :{epoch +1} loss : {avg_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZyGFzzcwKZD",
        "outputId": "9905c245-c69b-477f-abaf-58ddfac43b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9216666666666666\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "total = 0\n",
        "correct =0\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in test_Loder:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "    logist = model(batch_features)\n",
        "    _, predict = torch.max(logist, 1)\n",
        "    total = total + batch_labels.shape[0]\n",
        "    correct = correct + (predict == batch_labels).sum().item()\n",
        "  accuracy = correct/ total\n",
        "print(accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osVr3yST3Pm3",
        "outputId": "898bfdc5-53d4-416a-a5d4-b7459d4c9fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.97955\n"
          ]
        }
      ],
      "source": [
        "total_train =0\n",
        "correct_train =0\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in train_Loder:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "    logist = model(batch_features)\n",
        "    _, predict = torch.max(logist, 1)\n",
        "    total = total + batch_labels.shape[0]\n",
        "    correct = correct + (predict == batch_labels).sum().item()\n",
        "    accuracy = correct/ total\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDPCnWcc6ta3",
        "outputId": "a8b38014-624c-465e-ec20-09f57d8c7681"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-05 08:42:35,034] A new study created in memory with name: no-name-9ba297e3-d8e6-4282-ba55-01edddb940b0\n",
            "<ipython-input-57-16bf9c5daa29>:7: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  output_size = trial.suggest_int(f'n_nuron {i}', 32,256, 32)\n",
            "[I 2025-06-05 08:45:49,913] Trial 0 finished with value: 0.8859166666666667 and parameters: {'n_layers': 4, 'n_nuron 0': 64, 'dropout_l0': 0.20151616162722016, 'n_nuron 1': 192, 'dropout_l1': 0.3760427781798782, 'n_nuron 2': 160, 'dropout_l2': 0.24490265503569317, 'n_nuron 3': 128, 'dropout_l3': 0.309041701811585}. Best is trial 0 with value: 0.8859166666666667.\n",
            "[I 2025-06-05 08:49:23,900] Trial 1 finished with value: 0.8716666666666667 and parameters: {'n_layers': 5, 'n_nuron 0': 256, 'dropout_l0': 0.30371130784797634, 'n_nuron 1': 32, 'dropout_l1': 0.499493832249112, 'n_nuron 2': 32, 'dropout_l2': 0.2908319695632854, 'n_nuron 3': 64, 'dropout_l3': 0.28908961541428607, 'n_nuron 4': 160, 'dropout_l4': 0.34498234671790884}. Best is trial 0 with value: 0.8859166666666667.\n",
            "[I 2025-06-05 08:52:41,359] Trial 2 finished with value: 0.89125 and parameters: {'n_layers': 4, 'n_nuron 0': 256, 'dropout_l0': 0.27594196931348736, 'n_nuron 1': 64, 'dropout_l1': 0.21092018520262532, 'n_nuron 2': 128, 'dropout_l2': 0.39424035361103016, 'n_nuron 3': 96, 'dropout_l3': 0.24530043735825097}. Best is trial 2 with value: 0.89125.\n",
            "[I 2025-06-05 08:56:14,382] Trial 3 finished with value: 0.8643333333333333 and parameters: {'n_layers': 5, 'n_nuron 0': 64, 'dropout_l0': 0.3645940393224249, 'n_nuron 1': 128, 'dropout_l1': 0.49367623302300917, 'n_nuron 2': 32, 'dropout_l2': 0.34942346206355185, 'n_nuron 3': 64, 'dropout_l3': 0.34781917657203776, 'n_nuron 4': 192, 'dropout_l4': 0.3253661884467639}. Best is trial 2 with value: 0.89125.\n",
            "[I 2025-06-05 08:59:30,484] Trial 4 finished with value: 0.8714166666666666 and parameters: {'n_layers': 4, 'n_nuron 0': 64, 'dropout_l0': 0.21134948562332914, 'n_nuron 1': 96, 'dropout_l1': 0.48040445063114495, 'n_nuron 2': 128, 'dropout_l2': 0.4643126591280642, 'n_nuron 3': 160, 'dropout_l3': 0.3116739608551374}. Best is trial 2 with value: 0.89125.\n",
            "[I 2025-06-05 09:02:47,769] Trial 5 finished with value: 0.8873333333333333 and parameters: {'n_layers': 4, 'n_nuron 0': 160, 'dropout_l0': 0.4173375561333328, 'n_nuron 1': 96, 'dropout_l1': 0.42941259615950567, 'n_nuron 2': 224, 'dropout_l2': 0.32090212609882196, 'n_nuron 3': 96, 'dropout_l3': 0.21217634633760338}. Best is trial 2 with value: 0.89125.\n",
            "[I 2025-06-05 09:05:44,542] Trial 6 finished with value: 0.8793333333333333 and parameters: {'n_layers': 3, 'n_nuron 0': 64, 'dropout_l0': 0.41870452465444996, 'n_nuron 1': 192, 'dropout_l1': 0.3296188945763797, 'n_nuron 2': 160, 'dropout_l2': 0.2092708857793506}. Best is trial 2 with value: 0.89125.\n",
            "[I 2025-06-05 09:08:21,813] Trial 7 finished with value: 0.8925833333333333 and parameters: {'n_layers': 2, 'n_nuron 0': 96, 'dropout_l0': 0.20875192097007578, 'n_nuron 1': 256, 'dropout_l1': 0.3406299144009508}. Best is trial 7 with value: 0.8925833333333333.\n",
            "[I 2025-06-05 09:10:39,656] Trial 8 finished with value: 0.89175 and parameters: {'n_layers': 1, 'n_nuron 0': 128, 'dropout_l0': 0.28234407771045855}. Best is trial 7 with value: 0.8925833333333333.\n",
            "[I 2025-06-05 09:13:52,226] Trial 9 finished with value: 0.8905 and parameters: {'n_layers': 4, 'n_nuron 0': 256, 'dropout_l0': 0.22068374263735052, 'n_nuron 1': 96, 'dropout_l1': 0.43565775566953424, 'n_nuron 2': 128, 'dropout_l2': 0.4751999711696715, 'n_nuron 3': 224, 'dropout_l3': 0.3415192919138204}. Best is trial 7 with value: 0.8925833333333333.\n",
            "[I 2025-06-05 09:16:09,417] Trial 10 finished with value: 0.8915 and parameters: {'n_layers': 1, 'n_nuron 0': 160, 'dropout_l0': 0.49496845606279627}. Best is trial 7 with value: 0.8925833333333333.\n",
            "[I 2025-06-05 09:18:26,150] Trial 11 finished with value: 0.8869166666666667 and parameters: {'n_layers': 1, 'n_nuron 0': 128, 'dropout_l0': 0.2721148286382206}. Best is trial 7 with value: 0.8925833333333333.\n",
            "[I 2025-06-05 09:21:03,044] Trial 12 finished with value: 0.8919166666666667 and parameters: {'n_layers': 2, 'n_nuron 0': 128, 'dropout_l0': 0.2633792171871835, 'n_nuron 1': 256, 'dropout_l1': 0.2858835580083596}. Best is trial 7 with value: 0.8925833333333333.\n",
            "[I 2025-06-05 09:23:39,600] Trial 13 finished with value: 0.8950833333333333 and parameters: {'n_layers': 2, 'n_nuron 0': 192, 'dropout_l0': 0.24548597461099783, 'n_nuron 1': 256, 'dropout_l1': 0.28177981106625116}. Best is trial 13 with value: 0.8950833333333333.\n",
            "[I 2025-06-05 09:26:15,468] Trial 14 finished with value: 0.8988333333333334 and parameters: {'n_layers': 2, 'n_nuron 0': 192, 'dropout_l0': 0.3347515678985543, 'n_nuron 1': 256, 'dropout_l1': 0.2700810583994086}. Best is trial 14 with value: 0.8988333333333334.\n",
            "[I 2025-06-05 09:28:51,724] Trial 15 finished with value: 0.8978333333333334 and parameters: {'n_layers': 2, 'n_nuron 0': 192, 'dropout_l0': 0.3385410186447493, 'n_nuron 1': 192, 'dropout_l1': 0.2393809151292507}. Best is trial 14 with value: 0.8988333333333334.\n",
            "[I 2025-06-05 09:31:47,073] Trial 16 finished with value: 0.8948333333333334 and parameters: {'n_layers': 3, 'n_nuron 0': 192, 'dropout_l0': 0.33521044372305864, 'n_nuron 1': 192, 'dropout_l1': 0.2000915547619451, 'n_nuron 2': 256, 'dropout_l2': 0.40899600505857037}. Best is trial 14 with value: 0.8988333333333334.\n",
            "[I 2025-06-05 09:34:21,743] Trial 17 finished with value: 0.8938333333333334 and parameters: {'n_layers': 2, 'n_nuron 0': 224, 'dropout_l0': 0.3719440904458372, 'n_nuron 1': 224, 'dropout_l1': 0.252592427852493}. Best is trial 14 with value: 0.8988333333333334.\n",
            "[I 2025-06-05 09:37:15,550] Trial 18 finished with value: 0.8829166666666667 and parameters: {'n_layers': 3, 'n_nuron 0': 192, 'dropout_l0': 0.32613998339902167, 'n_nuron 1': 160, 'dropout_l1': 0.2480634950049711, 'n_nuron 2': 64, 'dropout_l2': 0.4998206942326531}. Best is trial 14 with value: 0.8988333333333334.\n",
            "[I 2025-06-05 09:39:51,120] Trial 19 finished with value: 0.8935 and parameters: {'n_layers': 2, 'n_nuron 0': 224, 'dropout_l0': 0.39626313833979393, 'n_nuron 1': 224, 'dropout_l1': 0.3072767323566588}. Best is trial 14 with value: 0.8988333333333334.\n"
          ]
        }
      ],
      "source": [
        "def def_model(trial):\n",
        "  n_layers = trial.suggest_int('n_layers', 1 ,5)\n",
        "  layers = []\n",
        "\n",
        "  input_size = X_train.shape[1]\n",
        "  for i in range(n_layers):\n",
        "    output_size = trial.suggest_int(f'n_nuron {i}', 32,256, 32)\n",
        "    layers.append(torch.nn.Linear(input_size, output_size))\n",
        "    layers.append(torch.nn.ReLU(inplace=True))\n",
        "    p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "    layers.append(torch.nn.Dropout(p))\n",
        "    input_size = output_size\n",
        "  layers.append(torch.nn.Linear(input_size, 10))\n",
        "\n",
        "  model = torch.nn.Sequential(*layers).to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  tuning_epoch = 5\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch_features, batch_labels in train_Loder:\n",
        "      batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "      logist = model(batch_features)\n",
        "      loss = criterion(logist, batch_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "    avg_loss = total_loss/len(train_Loder)\n",
        "    # print(f'epoch :{epoch +1} loss : {avg_loss}')\n",
        "\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct =0\n",
        "  with torch.no_grad():\n",
        "    for batch_features, batch_labels in test_Loder:\n",
        "      batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "      logist = model(batch_features)\n",
        "      _, predict = torch.max(logist, 1)\n",
        "      total = total + batch_labels.shape[0]\n",
        "      correct = correct + (predict == batch_labels).sum().item()\n",
        "    accuracy = correct/ total\n",
        "    # print(accuracy)\n",
        "  return accuracy\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(def_model, n_trials= 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBEm-ah0BAmG",
        "outputId": "0ef79d87-3250-4796-8ef4-78ad54946f0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8988333333333334"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDhQMxOeCAk_",
        "outputId": "60cd9bf5-8c74-420b-fde6-8bfe7d6d0183"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_layers': 2,\n",
              " 'n_nuron 0': 192,\n",
              " 'dropout_l0': 0.3347515678985543,\n",
              " 'n_nuron 1': 256,\n",
              " 'dropout_l1': 0.2700810583994086}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KihnvtpCCEG0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
